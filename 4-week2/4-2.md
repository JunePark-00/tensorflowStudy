# Deep Neural Networks for Time Series

> ~~~python
> import tensorflow as tf
> import numpy as np
> import matplotlib.pyplot as plt
> print(tf.__version__)
> ~~~
>
> ~~~python
> def plot_series(time, series, format="-", start=0, end=None):
>     plt.plot(time[start:end], series[start:end], format)
>     plt.xlabel("Time")
>     plt.ylabel("Value")
>     plt.grid(False)
> # **plot_series()** 함수는 임의의 시간 값 (time), 시계열 데이터 (series)를 입력받아 Matplotlib 그래프로 나타내는 함수입니다.
> 
> def trend(time, slope=0):
>     return slope * time
> '''
> **trend()** 함수는 경향성을 갖는 시계열 데이터를 반환합니다.
> **slope** 값에 따라서 시간에 따라 양의 경향성, 음의 경향성을 가질 수 있습니다.
> 예제에서는 길이 10 * 365 + 1의 시간 동안 시간에 따라 0.1의 기울기를 갖는 시계열 데이터를 만들었습니다.
> '''
> 
> def seasonal_pattern(season_time):
>     """Just an arbitrary pattern, you can change it if you wish"""
>     return np.where(season_time < 0.1,
>                     np.cos(season_time * 6 * np.pi),
>                     2 / np.exp(9 * season_time))
> '''
> seasonal_pattern() 함수는 입력 season_time에 대해서 0.1보다 작은 경우에는 np.cos(season_time * 6 * np.pi) 값을,
> 그렇지 않은 경우에는 2 / np.exp(9 * season_time)을 반환합니다.
> '''
> 
> def seasonality(time, period, amplitude=1, phase=0):
>     """Repeats the same pattern at each period"""
>     season_time = ((time + phase) % period) / period
>     return amplitude * seasonal_pattern(season_time)
> '''
> seasonality() 함수는 주어진 주기 period에 대해 특정 값을 반복하는 시계열 데이터를 반환하는 함수입니다.
> '''
> 
> def noise(time, noise_level=1, seed=None):
>     rnd = np.random.RandomState(seed)
>     return rnd.randn(len(time)) * noise_level
> 
> time = np.arange(10 * 365 + 1, dtype="float32")
> baseline = 10
> series = trend(time, 0.1)  
> baseline = 10
> amplitude = 40
> slope = 0.005
> noise_level = 3
> 
> # 불규칙한 패턴의 경우 일반적으로 White Noise라고 칭하며 평균이 0이며 일정한 분산을 가진 정규분포에서 추출된 임의의 수치라고 가정하고 있습니다. noise() 함수는 0에서 noise_level 값 사이의 임의의 실수를 갖는 시계열 데이터를 반환합니다.
> 
> # Create the series
> series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)
> # Update with noise
> series += noise(time, noise_level, seed=51)
> 
> # 시계열 데이터의 앞부분 3000개를 훈련용, 나머지를 검증용 데이터로 분류
> split_time = 3000
> time_train = time[:split_time]
> x_train = series[:split_time]
> time_valid = time[split_time:]
> x_valid = series[split_time:]
> 
> window_size = 20
> batch_size = 32
> shuffle_buffer_size = 1000
> 
> plot_series(time, series)
> ~~~
>
> **windowed_dataset()**: windows dataset 호출
>
> 파라미터 : the size of the batches to use when training, the size of the shuffle buffer, which determines how the data will be shuffled
>
> Step1. tf.data.dataset을 이용하여 시리즈에서 데이터셋 생성 -> from_tensor_slices 메서드를 사용하여 시리즈 전달
>
> Step2. 데이터 세트의 window method를 사용. window_size를 기반으로 데이터를 적절한 창으로 분할 -> 각각 한 시간씩 이동 - > drop 나머지를 true로 설정하여 모두 동일한 크기로 유지
>
> Step3. 데이터 평면화. window_size + 1의 크기의 chunks로 평평해질 것임. 평평해지면 셔플이 쉬워짐
>
> Step4. 셔플을 호출하고 셔플 버퍼를 전달. 셔플 버퍼를 사용하면 작업 속도가 약간 빨라짐
>
> > 예를 들어 데이터세트에 100,000개의 항목이 있지만 버퍼를 천으로 설정합니다. 버퍼를 처음 1,000개의 요소로 채울 것입니다. 무작위로 그 중 하나를 선택하십시오. 그리고 나서 그것을 1,000으로 대체하고 다시 무작위로 선택하기 전에 첫 번째 요소를 선택하는 식입니다. 이렇게 하면 초대형 데이터 세트에서 임의의 요소를 효과적으로 속도를 높이는 더 작은 숫자로부터 선택할 수 있습니다. 
>
> Step5. 섞인 데이터 세트는 마지막을 제외한 모든 요소인 xs와 마지막 요소인 y로 분할. 
>
> Step6. 선택한 배치 크기로 배치되어 반환

> ~~~python
> def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
>   dataset = tf.data.Dataset.from_tensor_slices(series)
>   dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)
>   dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))
>   dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))
>   dataset = dataset.batch(batch_size).prefetch(1)
>   return dataset
> ~~~
>
> ~~~python
> dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)
> 
> 
> model = tf.keras.models.Sequential([
>     tf.keras.layers.Dense(100, input_shape=[window_size], activation="relu"), 
>     tf.keras.layers.Dense(10, activation="relu"), 
>     tf.keras.layers.Dense(1)
> ])
> 
> model.compile(loss="mse", optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9))
> model.fit(dataset,epochs=100,verbose=0)
> 
> ~~~
>
> ~~~python
> forecast = []
> for time in range(len(series) - window_size):
>   forecast.append(model.predict(series[time:time + window_size][np.newaxis]))
> 
> forecast = forecast[split_time-window_size:]
> results = np.array(forecast)[:, 0, 0]
> 
> 
> plt.figure(figsize=(10, 6))
> 
> plot_series(time_valid, x_valid)
> plot_series(time_valid, results)
> ~~~
>
> ~~~python
> tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()
> ~~~
>